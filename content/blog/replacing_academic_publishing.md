# Replacing Academic Publishing

How do you justify AI, given the risks? How about living long and living healthy with AI accellerated science? We are promised AI agents as brilliant scientists - and I think that is likely.

But. We need to get the academic publishing system out of the way. Why? Because no amount of automation can reason about data that isn't shared.

Suppose my lab just completed a very expensive study that generated a huge dataset. Its been checked and double-checked. I should release it immediately, including all the methods documentation. Right?

Wrong. First, the grad students or postdocs who did the work need to publish their paper. If they let that data out, someone might use it to discover something amazing before they do. The glory is in the discovery, not in the brilliant creation of the data.

Not only do we delay access to the data while we explore it, developing and testing hypotheses, it is further delayed by the glacial publishing cycle. From the time that the dataset was finished to the time someone can download it might be three years.

This utterly hamstrings the AI science revolution. If one AI-boosted lab generates a dataset, all the other labs should have access as soon as the quality checks are finished. And when they use it to generate new findings, they should also share their results instantly. We can't compress decades of research into years and months if each cycle involves a journal.

In other fields, aRxiv has largely supplanted journals but in biology, preprints in biorXiv are nice but they don't count. 

It all boils down to giving credit to the people who do the work and what work is considered valuable. The peer-review system is not just about good science, it is the gatekeeper for careers.

So, what do we want? Stick to our current paradigm for keeping score? Or do we want to solve problems and save lives?

The peer-review process takes time and it runs on the backs of scientists who agree to take significant time away from their own research to do a review. A good review is a big ask, maybe a whole day. 

And no one could possibly afford to do laboratory experiments to reproduce the author's work. 

This was already a bad situation. Unnecessary delays in the dissemination of results delay cures. Delay in cures costs suffering and lives. Suppose, after it was finally published, someone else used your data in developing a life-saving drug. Let's say that the drug might have been developed a year earlier if you had released the data immediately. Now imagine yourself on a stage, explaining why you delayed the release to the families of patients who died in the previous year.

But if AI can accellerate our work, compressing years of progress into months, this problem is critical. We want the output of one AI-boosted lab to be available to all the other AI labs as soon as it is available. 

And if it's going to get into a good journal, they need to do something interesting with the data, use it to discover something worthwhile. This isn't a matter of petty academic politics, those students
Genuine automation of science to dramatically improve health outcomes is a central justification for developing AI, despite its many risks.Why 
